{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 1 -- Setup & Collection\n",
    "\n",
    "Pull Tweets from the Twitter API and collect **all Tweets from 30 tech thought leaders and news outlets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load lib codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/predicting_stock_market_trends_with_Twitter/ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/work/predicting_stock_market_trends_with_Twitter/')\n",
    "\n",
    "from lib import *\n",
    "# suppress_warnings()\n",
    "from lib.twitter_keys import my_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/conda/envs/python2/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: pyquery in /opt/conda/envs/python2/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: tweepy in /opt/conda/envs/python2/lib/python2.7/site-packages\r\n",
      "Requirement already satisfied: lxml>=2.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pyquery)\r\n",
      "Requirement already satisfied: cssselect>0.7.9 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pyquery)\r\n",
      "Requirement already satisfied: requests>=2.4.3 in /opt/conda/envs/python2/lib/python2.7/site-packages (from tweepy)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.1 in /opt/conda/envs/python2/lib/python2.7/site-packages (from tweepy)\r\n",
      "Requirement already satisfied: six>=1.7.3 in /opt/conda/envs/python2/lib/python2.7/site-packages (from tweepy)\r\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from requests-oauthlib>=0.4.1->tweepy)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo pyquery tweepy\n",
    "import pymongo\n",
    "import tweepy\n",
    "# from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Replace the API_KEY and API_SECRET with your application's key and secret\n",
    "auth = tweepy.AppAuthHandler(my_keys['CONSUMER_KEY'], my_keys['CONSUMER_SECRET'])\n",
    "\n",
    "# Authorize twitter, initialize tweepy\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cli = pymongo.MongoClient(host='35.163.253.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'tweets_collection', u'task_collection']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates when you put data in \n",
    "task_collection = cli.twitter_db.task_collection\n",
    "tweets_collection = cli.twitter_db.tweets_collection\n",
    "cli.twitter_db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "3132\n"
     ]
    }
   ],
   "source": [
    "print(task_collection.count())\n",
    "print(tweets_collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task_collection.drop()\n",
    "tweets_collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml==3.5.0 (from -r requirements.txt (line 1))\n",
      "  Using cached lxml-3.5.0.tar.gz\n",
      "Collecting pyquery==1.2.10 (from -r requirements.txt (line 2))\n",
      "  Using cached pyquery-1.2.10-py2-none-any.whl\n",
      "Requirement already satisfied: cssselect>0.7.9 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pyquery==1.2.10->-r requirements.txt (line 2))\n",
      "Building wheels for collected packages: lxml\n",
      "  Running setup.py bdist_wheel for lxml ... \u001b[?25l-\b \b\\\b \b|\b \berror\n",
      "  Complete output from command /opt/conda/envs/python2/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-lci9sr/lxml/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmpAlVFcrpip-wheel- --python-tag cp27:\n",
      "  Building lxml version 3.5.0.\n",
      "  Building without Cython.\n",
      "  ERROR: /bin/sh: 1: xslt-config: not found\n",
      "  \n",
      "  ** make sure the development packages of libxml2 and libxslt are installed **\n",
      "  \n",
      "  Using build configuration of libxslt\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-2.7\n",
      "  creating build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/__init__.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/usedoctest.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/pyclasslookup.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/_elementpath.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/cssselect.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/builder.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/sax.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/doctestcompare.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/ElementInclude.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/__init__.py -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/soupparser.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/_html5builder.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/formfill.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/__init__.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/usedoctest.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/ElementSoup.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/html5parser.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/_setmixin.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/builder.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/defs.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/_diffcommand.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/clean.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  copying src/lxml/html/diff.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/isoschematron\n",
      "  copying src/lxml/isoschematron/__init__.py -> build/lib.linux-x86_64-2.7/lxml/isoschematron\n",
      "  copying src/lxml/lxml.etree.h -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/lxml.etree_api.h -> build/lib.linux-x86_64-2.7/lxml\n",
      "  copying src/lxml/includes/config.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xmlerror.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/tree.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/schematron.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/htmlparser.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xmlparser.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xslt.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xinclude.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/uri.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/dtdvalid.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xpath.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/xmlschema.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/relaxng.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/etreepublic.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/c14n.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/etree_defs.h -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  copying src/lxml/includes/lxml-version.h -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/rng\n",
      "  copying src/lxml/isoschematron/resources/rng/iso-schematron.rng -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/rng\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "  copying src/lxml/isoschematron/resources/xsl/XSD2Schtrn.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "  copying src/lxml/isoschematron/resources/xsl/RNG2Schtrn.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "  creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_schematron_message.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_schematron_skeleton_for_xslt1.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_dsdl_include.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_svrl_for_xslt1.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_abstract_expand.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/readme.txt -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "  running build_ext\n",
      "  building 'lxml.etree' extension\n",
      "  creating build/temp.linux-x86_64-2.7\n",
      "  creating build/temp.linux-x86_64-2.7/src\n",
      "  creating build/temp.linux-x86_64-2.7/src/lxml\n",
      "  gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -Isrc/lxml/includes -I/opt/conda/envs/python2/include/python2.7 -c src/lxml/lxml.etree.c -o build/temp.linux-x86_64-2.7/src/lxml/lxml.etree.o -w\n",
      "  In file included from src/lxml/lxml.etree.c:323:0:\n",
      "  src/lxml/includes/etree_defs.h:14:31: fatal error: libxml/xmlversion.h: No such file or directory\n",
      "   #include \"libxml/xmlversion.h\"\n",
      "                                 ^\n",
      "  compilation terminated.\n",
      "  Compile failed: command 'gcc' failed with exit status 1\n",
      "  creating tmp\n",
      "  cc -I/usr/include/libxml2 -c /tmp/xmlXPathInitI9pj4p.c -o tmp/xmlXPathInitI9pj4p.o\n",
      "  /tmp/xmlXPathInitI9pj4p.c:1:26: fatal error: libxml/xpath.h: No such file or directory\n",
      "   #include \"libxml/xpath.h\"\n",
      "                            ^\n",
      "  compilation terminated.\n",
      "  *********************************************************************************\n",
      "  Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?\n",
      "  *********************************************************************************\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for lxml\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for lxml\n",
      "Failed to build lxml\n",
      "Installing collected packages: lxml, pyquery\n",
      "  Found existing installation: lxml 3.7.3\n",
      "    Uninstalling lxml-3.7.3:\n",
      "      Successfully uninstalled lxml-3.7.3\n",
      "  Running setup.py install for lxml ... \u001b[?25l-\b \b\\\b \b|\b \berror\n",
      "    Complete output from command /opt/conda/envs/python2/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-lci9sr/lxml/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-mMwKed-record/install-record.txt --single-version-externally-managed --compile:\n",
      "    Building lxml version 3.5.0.\n",
      "    Building without Cython.\n",
      "    ERROR: /bin/sh: 1: xslt-config: not found\n",
      "    \n",
      "    ** make sure the development packages of libxml2 and libxslt are installed **\n",
      "    \n",
      "    Using build configuration of libxslt\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-2.7\n",
      "    creating build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/__init__.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/usedoctest.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/pyclasslookup.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/_elementpath.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/cssselect.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/builder.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/sax.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/doctestcompare.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/ElementInclude.py -> build/lib.linux-x86_64-2.7/lxml\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/__init__.py -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/soupparser.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/_html5builder.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/formfill.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/__init__.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/usedoctest.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/ElementSoup.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/html5parser.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/_setmixin.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/builder.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/defs.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/_diffcommand.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/clean.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    copying src/lxml/html/diff.py -> build/lib.linux-x86_64-2.7/lxml/html\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/isoschematron\n",
      "    copying src/lxml/isoschematron/__init__.py -> build/lib.linux-x86_64-2.7/lxml/isoschematron\n",
      "    copying src/lxml/lxml.etree.h -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/lxml.etree_api.h -> build/lib.linux-x86_64-2.7/lxml\n",
      "    copying src/lxml/includes/config.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xmlerror.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/tree.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/schematron.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/htmlparser.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xmlparser.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xslt.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xinclude.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/uri.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/dtdvalid.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xpath.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/xmlschema.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/relaxng.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/etreepublic.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/c14n.pxd -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/etree_defs.h -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    copying src/lxml/includes/lxml-version.h -> build/lib.linux-x86_64-2.7/lxml/includes\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/rng\n",
      "    copying src/lxml/isoschematron/resources/rng/iso-schematron.rng -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/rng\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "    copying src/lxml/isoschematron/resources/xsl/XSD2Schtrn.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "    copying src/lxml/isoschematron/resources/xsl/RNG2Schtrn.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl\n",
      "    creating build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_schematron_message.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_schematron_skeleton_for_xslt1.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_dsdl_include.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_svrl_for_xslt1.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/iso_abstract_expand.xsl -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    copying src/lxml/isoschematron/resources/xsl/iso-schematron-xslt1/readme.txt -> build/lib.linux-x86_64-2.7/lxml/isoschematron/resources/xsl/iso-schematron-xslt1\n",
      "    running build_ext\n",
      "    building 'lxml.etree' extension\n",
      "    creating build/temp.linux-x86_64-2.7\n",
      "    creating build/temp.linux-x86_64-2.7/src\n",
      "    creating build/temp.linux-x86_64-2.7/src/lxml\n",
      "    gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -Isrc/lxml/includes -I/opt/conda/envs/python2/include/python2.7 -c src/lxml/lxml.etree.c -o build/temp.linux-x86_64-2.7/src/lxml/lxml.etree.o -w\n",
      "    In file included from src/lxml/lxml.etree.c:323:0:\n",
      "    src/lxml/includes/etree_defs.h:14:31: fatal error: libxml/xmlversion.h: No such file or directory\n",
      "     #include \"libxml/xmlversion.h\"\n",
      "                                   ^\n",
      "    compilation terminated.\n",
      "    Compile failed: command 'gcc' failed with exit status 1\n",
      "    cc -I/usr/include/libxml2 -c /tmp/xmlXPathInitIvQa8n.c -o tmp/xmlXPathInitIvQa8n.o\n",
      "    /tmp/xmlXPathInitIvQa8n.c:1:26: fatal error: libxml/xpath.h: No such file or directory\n",
      "     #include \"libxml/xpath.h\"\n",
      "                              ^\n",
      "    compilation terminated.\n",
      "    *********************************************************************************\n",
      "    Could not find function xmlCheckVersion in library libxml2. Is libxml2 installed?\n",
      "    *********************************************************************************\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[?25h  Rolling back uninstall of lxml\n",
      "\u001b[31mCommand \"/opt/conda/envs/python2/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-lci9sr/lxml/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-mMwKed-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-lci9sr/lxml/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chdir('//home/jovyan/work/predicting_stock_market_trends_with_Twitter/tools/GetOldTweets-python-master')\n",
    "!pip install -r requirements.txt\n",
    "import got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implement distributed processing from scratch - run this on multiple AWS instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_30_df = pd.read_csv('/home/jovyan/work/predicting_stock_market_trends_with_Twitter/data/twitter_users_30.csv')\n",
    "handle = list(twitter_30_df['Handle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookup_list = []\n",
    "for h in handle:\n",
    "    lookup_dict = {'handle': h,\n",
    "                   'status': 'queuing'}\n",
    "    lookup_list.append(lookup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'handle': 'BarackObama', 'status': 'queuing'},\n",
       " {'handle': 'cnnbrk', 'status': 'queuing'},\n",
       " {'handle': 'BillGates', 'status': 'queuing'},\n",
       " {'handle': 'realDonaldTrump', 'status': 'queuing'},\n",
       " {'handle': 'TheEconomist', 'status': 'queuing'},\n",
       " {'handle': 'aplusk', 'status': 'queuing'},\n",
       " {'handle': 'HillaryClinton', 'status': 'queuing'},\n",
       " {'handle': 'TechCrunch', 'status': 'queuing'},\n",
       " {'handle': 'elonmusk', 'status': 'queuing'},\n",
       " {'handle': 'NewYorker', 'status': 'queuing'},\n",
       " {'handle': 'mcuban', 'status': 'queuing'},\n",
       " {'handle': 'jack', 'status': 'queuing'},\n",
       " {'handle': 'MarketWatch', 'status': 'queuing'},\n",
       " {'handle': 'CNBC', 'status': 'queuing'},\n",
       " {'handle': 'ForbesTech', 'status': 'queuing'},\n",
       " {'handle': 'sacca', 'status': 'queuing'},\n",
       " {'handle': 'SAI', 'status': 'queuing'},\n",
       " {'handle': 'paulg', 'status': 'queuing'},\n",
       " {'handle': 'themotleyfool', 'status': 'queuing'},\n",
       " {'handle': 'ReformedBroker', 'status': 'queuing'},\n",
       " {'handle': 'StockTwits', 'status': 'queuing'},\n",
       " {'handle': 'cnntech', 'status': 'queuing'},\n",
       " {'handle': 'MONEY', 'status': 'queuing'},\n",
       " {'handle': 'Carl_C_Icahn', 'status': 'queuing'},\n",
       " {'handle': 'sgblank', 'status': 'queuing'},\n",
       " {'handle': 'investorslive', 'status': 'queuing'},\n",
       " {'handle': 'markflowchatter', 'status': 'queuing'},\n",
       " {'handle': 'MarkYusko', 'status': 'queuing'},\n",
       " {'handle': 'FinancialTimes', 'status': 'queuing'},\n",
       " {'handle': 'tim_cook', 'status': 'queuing'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for dictionary in lookup_list:\n",
    "    task_collection.insert_one(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets_to_mongo(lookup):\n",
    "\n",
    "    maxTweets = 10 # Some arbitrary large number\n",
    "    tweetsPerQry = 200  # this is the max the API permits\n",
    "\n",
    "    # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "    # else default to no lower limit, go as far back as API allows\n",
    "    sinceId = None\n",
    "\n",
    "    # If results only below a specific ID are, set max_id to that ID.\n",
    "    # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "    max_id = -1E10\n",
    "\n",
    "    tweetCount = 0\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry)\n",
    "                else:\n",
    "                    new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "                                                    since_id=sinceId)\n",
    "            else:\n",
    "\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "                                                    max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "                                                    max_id=str(max_id - 1),\n",
    "                                                    since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                tweet_dict = {'username': tweet.user.screen_name,\n",
    "                              'timestamp': tweet.created_at, \n",
    "                              'text': tweet.text.encode(\"utf-8\")}\n",
    "        #             writer = csv.writer(f)\n",
    "        #             writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        #             writer.writerows(outtweets)\n",
    "                mongo_response = tweets_collection.insert_one(tweet_dict)\n",
    "\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets for user: {1}\".format(tweetCount, lookup))\n",
    "            max_id = new_tweets[-1].id  \n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "\n",
    "    print (\"Downloaded {0} tweets for user: {1} & saved to Mongo\\n\".format(tweetCount, lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#THIS WAS FOR FEEDING IN A LIST\n",
    "# def get_tweets_to_mongo(lookup):\n",
    "\n",
    "#     maxTweets = 10 # Some arbitrary large number\n",
    "#     tweetsPerQry = 200  # this is the max the API permits\n",
    "\n",
    "#     for l in lookup:\n",
    "#         # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "#         # else default to no lower limit, go as far back as API allows\n",
    "#         sinceId = None\n",
    "\n",
    "#         # If results only below a specific ID are, set max_id to that ID.\n",
    "#         # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "#         max_id = -1E10\n",
    "\n",
    "#         tweetCount = 0\n",
    "#         while tweetCount < maxTweets:\n",
    "#             try:\n",
    "#                 if (max_id <= 0):\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry)\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "#                                                     since_id=sinceId)\n",
    "#                 else:\n",
    "\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "#                                                     max_id=str(max_id - 1))\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = lookup, count=tweetsPerQry,\n",
    "#                                                     max_id=str(max_id - 1),\n",
    "#                                                     since_id=sinceId)\n",
    "#                 if not new_tweets:\n",
    "#                     print(\"No more tweets found\")\n",
    "#                     break\n",
    "#                 for tweet in new_tweets:\n",
    "#                     tweet_dict = {'username': tweet.user.screen_name,\n",
    "#                                   'timestamp': tweet.created_at, \n",
    "#                                   'text': tweet.text.encode(\"utf-8\")}\n",
    "#         #             writer = csv.writer(f)\n",
    "#         #             writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "#         #             writer.writerows(outtweets)\n",
    "#                     mongo_response = tweets_collection.insert_one(tweet_dict)\n",
    "\n",
    "#                 tweetCount += len(new_tweets)\n",
    "#                 print(\"Downloaded {0} tweets for user: {1}\".format(tweetCount, l))\n",
    "#                 max_id = new_tweets[-1].id  \n",
    "\n",
    "#             except tweepy.TweepError as e:\n",
    "#                 # Just exit if any error\n",
    "#                 print(\"some error : \" + str(e))\n",
    "#                 break\n",
    "\n",
    "#         print (\"Downloaded {0} tweets for user: {1} & saved to Mongo\\n\".format(tweetCount, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f0ed6169280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = task_collection.find_one_and_delete({'status':'queuing'})\n",
    "task_handle = task['handle']\n",
    "task_collection.insert_one({'handle': task_handle,\n",
    "                            'status':'in progress'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "ERROR for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama\n",
      "Downloaded 200 tweets for user: BarackObama & saved to Mongo\n",
      "\n",
      "complete for BarackObama\n",
      "pulling tweets for BarackObama\n"
     ]
    }
   ],
   "source": [
    "task = task_collection.find_one_and_delete({'status':'queuing'})\n",
    "task_handle = task['handle']\n",
    "task_collection.insert_one({'handle': task_handle,\n",
    "                            'status':'in progress'})\n",
    "\n",
    "while task:\n",
    "    print(\"pulling tweets for {}\".format(task_handle))\n",
    "    try:\n",
    "        get_tweets_to_mongo(task_handle)\n",
    "        task_collection.insert_one({'handle': task_handle,\n",
    "                                        'status': 'complete'})\n",
    "        print(\"complete for {}\".format(task_handle))\n",
    "    except:\n",
    "        task_collection.find_one_and_delete({'handle': task_handle,\n",
    "                                                 'status':'in progress'})\n",
    "        task_collection.insert_one({'handle': task_handle,\n",
    "                                        'status': 'incomplete'})\n",
    "        print(\"ERROR for {}\".format(task_handle))\n",
    "    task = task_collection.find_one_and_delete({'status':'queuing'})\n",
    "    task_handle = task['handle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "curs = task_collection.find()\n",
    "list_of_docs = []\n",
    "for i in range(curs.count()):\n",
    "    list_of_docs.append(curs.next())\n",
    "    df = pd.DataFrame(list_of_docs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def get_tweets_to_mongo(lookup):\n",
    "\n",
    "#     maxTweets = 10000000 # Some arbitrary large number\n",
    "#     tweetsPerQry = 200  # this is the max the API permits\n",
    "\n",
    "#     for l in lookup:\n",
    "#         # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "#         # else default to no lower limit, go as far back as API allows\n",
    "#         sinceId = None\n",
    "\n",
    "#         # If results only below a specific ID are, set max_id to that ID.\n",
    "#         # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "#         max_id = -1E10\n",
    "\n",
    "#         tweetCount = 0\n",
    "#         while tweetCount < maxTweets:\n",
    "#             try:\n",
    "#                 if (max_id <= 0):\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = 'aplusk', count=tweetsPerQry)\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = 'aplusk', count=tweetsPerQry,\n",
    "#                                                     since_id=sinceId)\n",
    "#                 else:\n",
    "\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = 'aplusk', count=tweetsPerQry,\n",
    "#                                                     max_id=str(max_id - 1))\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = 'aplusk', count=tweetsPerQry,\n",
    "#                                                     max_id=str(max_id - 1),\n",
    "#                                                     since_id=sinceId)\n",
    "#                 if not new_tweets:\n",
    "#                     print(\"No more tweets found\")\n",
    "#                     break\n",
    "#                 for tweet in new_tweets:\n",
    "#                     tweet_dict = {'username': tweet.user.screen_name,\n",
    "#                                   'timestamp': tweet.created_at, \n",
    "#                                   'text': tweet.text.encode(\"utf-8\")}\n",
    "#         #             writer = csv.writer(f)\n",
    "#         #             writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "#         #             writer.writerows(outtweets)\n",
    "#                     mongo_response = tweets_collection.insert_one(tweet_dict)\n",
    "\n",
    "#                 tweetCount += len(new_tweets)\n",
    "#                 print(\"Downloaded {0} tweets for user: {1}\".format(tweetCount, l))\n",
    "#                 max_id = new_tweets[-1].id  \n",
    "\n",
    "#             except tweepy.TweepError as e:\n",
    "#                 # Just exit if any error\n",
    "#                 print(\"some error : \" + str(e))\n",
    "#                 break\n",
    "\n",
    "#         print (\"Downloaded {0} tweets for user: {1} & saved to Mongo\\n\".format(tweetCount, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "get_tweets_to_mongo(handle)\n",
    "end = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tweets_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "curs = tweets_collection.find()\n",
    "list_of_docs = []\n",
    "for i in range(curs.count()):\n",
    "    list_of_docs.append(curs.next())\n",
    "    df = pd.DataFrame(list_of_docs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
