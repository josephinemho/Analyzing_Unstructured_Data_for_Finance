{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 -- Setup & Collection\n",
    "\n",
    "Pull Tweets from the Twitter API and collect **all Tweets from 30 tech thought leaders and news outlets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load lib codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter/')\n",
    "\n",
    "from lib import *\n",
    "suppress_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create database with PyMongo and install Tweepy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-3.4.0-cp35-cp35m-manylinux1_x86_64.whl (359kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tweepy\n",
      "  Downloading tweepy-3.5.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.4.1 (from tweepy)\n",
      "  Downloading requests_oauthlib-0.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.7.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests>=2.4.3 in /opt/conda/lib/python3.5/site-packages (from tweepy)\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.4.1->tweepy)\n",
      "  Downloading oauthlib-2.0.2.tar.gz (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 3.3MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: oauthlib\n",
      "  Running setup.py bdist_wheel for oauthlib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/84/98/7a/fba7268f61097bea6081cbe5480bc439b38975748ea7684fd5\n",
      "Successfully built oauthlib\n",
      "Installing collected packages: pymongo, oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-2.0.2 pymongo-3.4.0 requests-oauthlib-0.8.0 tweepy-3.5.0\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "cli = pymongo.MongoClient(host='35.163.253.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cli.drop_database('twitter_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'local']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a reference. This is not going to instantiate until you put data in it:\n",
    "twitter_db = cli.twitter_db\n",
    "cli.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'local']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_collection = cli.twitter_db.twitter_collection\n",
    "cli.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from Twitter API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d8dd8a91c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ae5294a98436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter_keys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'lib'"
     ]
    }
   ],
   "source": [
    "from lib.twitter_keys import my_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables that contains the user credentials to access Twitter API \n",
    "access_token = my_keys['ACCESS_TOKEN']\n",
    "access_token_secret = my_keys['ACCESS_SECRET']\n",
    "consumer_key = my_keys['CONSUMER_KEY']\n",
    "consumer_secret = my_keys['CONSUMER_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Carl Icahn</td>\n",
       "      <td>Carl Icahn</td>\n",
       "      <td>332,000</td>\n",
       "      <td>Chairman of Icahn Enterprises L.P.; etc., etc....</td>\n",
       "      <td>Thought Leader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business Insider Tech</td>\n",
       "      <td>SAI</td>\n",
       "      <td>1,440,000</td>\n",
       "      <td>The latest tech news from @BusinessInsider.</td>\n",
       "      <td>News Outlet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Forbes Tech News</td>\n",
       "      <td>ForbesTech</td>\n",
       "      <td>2,600,000</td>\n",
       "      <td>Tech news and insights from @Forbes.</td>\n",
       "      <td>News Outlet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name      Handle   Followers   \\\n",
       "23             Carl Icahn  Carl Icahn     332,000    \n",
       "16  Business Insider Tech         SAI   1,440,000    \n",
       "14       Forbes Tech News  ForbesTech   2,600,000    \n",
       "\n",
       "                                          Description            Type  \\\n",
       "23  Chairman of Icahn Enterprises L.P.; etc., etc....  Thought Leader   \n",
       "16        The latest tech news from @BusinessInsider.     News Outlet   \n",
       "14               Tech news and insights from @Forbes.     News Outlet   \n",
       "\n",
       "    Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  \n",
       "23         NaN         NaN         NaN         NaN  \n",
       "16         NaN         NaN         NaN         NaN  \n",
       "14         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_30_df = pd.read_csv('/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter/data/twitter_users_30.csv')\n",
    "twitter_30_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = list(twitter_30_df['Handle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BarackObama',\n",
       " 'cnnbrk',\n",
       " 'BillGates',\n",
       " 'realDonaldTrump',\n",
       " 'TheEconomist',\n",
       " 'aplusk',\n",
       " 'HillaryClinton',\n",
       " 'TechCrunch',\n",
       " 'elonmusk',\n",
       " 'NewYorker',\n",
       " 'mcuban',\n",
       " 'jack',\n",
       " 'MarketWatch',\n",
       " 'CNBC',\n",
       " 'ForbesTech',\n",
       " 'sacca',\n",
       " 'SAI',\n",
       " 'paulg',\n",
       " 'themotleyfool',\n",
       " 'ReformedBroker',\n",
       " 'StockTwits',\n",
       " 'cnntech',\n",
       " 'MONEY',\n",
       " 'Carl Icahn',\n",
       " 'sgblank',\n",
       " 'investorslive',\n",
       " 'markflowchatter',\n",
       " 'MarkYusko',\n",
       " 'FinancialTimes',\n",
       " 'tim_cook']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Most codes on the internet use the Access Token Auth method, which is limited to 180 Requests/15 mins limit (18,000 tweets/15 mins). If you download 18K tweets before 15 mins, you won’t be able to get any more results until your 15 min window expires and you search again.\n",
    "\n",
    "**Solution:** Use Application only Auth instead of the Access Token Auth. Application only auth has higher limits - 450 request/sec (45,000 tweets/15-min), which is 2.5 times more than the Access Token Limit.\n",
    "\n",
    "The secret is the AppAuthHandler instead of the more frequent OAuthHandler which you find being used in lots of code samples. This sets up App-only Auth and gives you higher limits. Also as an added bonus notice the wait_on_rate_limit & wait_on_rate_limit_notify flags set to true. What this does is make the Tweepy API call auto wait (sleep) when it hits the rate limit and continue upon expiry of the window. This avoids you to have to program this part manually, which as you’ll shortly see makes your program much more simple and elegant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle = ['aplusk', 'BarackObama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aplusk', 'BarackObama']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Replace the API_KEY and API_SECRET with your application's key and secret:\n",
    "auth = tweepy.AppAuthHandler(my_keys['CONSUMER_KEY'], my_keys['CONSUMER_SECRET'])\n",
    "\n",
    "# Authorize twitter, initialize tweepy\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000000 tweets\n",
      "Downloaded 100 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 300 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 500 tweets\n",
      "Downloaded 600 tweets\n",
      "Downloaded 700 tweets\n",
      "Downloaded 800 tweets\n",
      "Downloaded 900 tweets\n",
      "Downloaded 1000 tweets\n",
      "Downloaded 1100 tweets\n",
      "Downloaded 1200 tweets\n",
      "Downloaded 1300 tweets\n",
      "Downloaded 1400 tweets\n",
      "Downloaded 1500 tweets\n",
      "Downloaded 1600 tweets\n",
      "Downloaded 1700 tweets\n",
      "Downloaded 1800 tweets\n",
      "Downloaded 1900 tweets\n",
      "Downloaded 2000 tweets\n",
      "Downloaded 2100 tweets\n",
      "Downloaded 2200 tweets\n",
      "Downloaded 2300 tweets\n",
      "Downloaded 2400 tweets\n",
      "Downloaded 2500 tweets\n",
      "Downloaded 2600 tweets\n",
      "Downloaded 2700 tweets\n",
      "Downloaded 2800 tweets\n",
      "Downloaded 2900 tweets\n",
      "Downloaded 3000 tweets\n",
      "Downloaded 3100 tweets\n",
      "Downloaded 3200 tweets\n",
      "Downloaded 3300 tweets\n",
      "Downloaded 3400 tweets\n",
      "Downloaded 3500 tweets\n",
      "Downloaded 3600 tweets\n",
      "Downloaded 3700 tweets\n",
      "Downloaded 3800 tweets\n",
      "Downloaded 3900 tweets\n",
      "Downloaded 4000 tweets\n",
      "Downloaded 4100 tweets\n",
      "Downloaded 4200 tweets\n",
      "Downloaded 4300 tweets\n",
      "Downloaded 4400 tweets\n",
      "Downloaded 4500 tweets\n",
      "Downloaded 4600 tweets\n",
      "Downloaded 4700 tweets\n",
      "Downloaded 4800 tweets\n",
      "Downloaded 4900 tweets\n",
      "Downloaded 5000 tweets\n",
      "Downloaded 5100 tweets\n",
      "Downloaded 5200 tweets\n",
      "Downloaded 5300 tweets\n",
      "Downloaded 5400 tweets\n",
      "Downloaded 5500 tweets\n",
      "Downloaded 5600 tweets\n",
      "Downloaded 5700 tweets\n",
      "Downloaded 5800 tweets\n",
      "Downloaded 5900 tweets\n",
      "Downloaded 6000 tweets\n",
      "Downloaded 6100 tweets\n",
      "Downloaded 6200 tweets\n",
      "Downloaded 6300 tweets\n",
      "Downloaded 6400 tweets\n",
      "Downloaded 6500 tweets\n",
      "Downloaded 6600 tweets\n",
      "Downloaded 6700 tweets\n",
      "Downloaded 6800 tweets\n",
      "Downloaded 6900 tweets\n",
      "Downloaded 7000 tweets\n",
      "Downloaded 7100 tweets\n",
      "Downloaded 7200 tweets\n",
      "Downloaded 7300 tweets\n",
      "Downloaded 7400 tweets\n",
      "Downloaded 7500 tweets\n",
      "Downloaded 7600 tweets\n",
      "Downloaded 7700 tweets\n",
      "Downloaded 7800 tweets\n",
      "Downloaded 7900 tweets\n",
      "Downloaded 8000 tweets\n",
      "Downloaded 8100 tweets\n",
      "Downloaded 8200 tweets\n",
      "Downloaded 8300 tweets\n",
      "Downloaded 8400 tweets\n",
      "Downloaded 8500 tweets\n",
      "Downloaded 8600 tweets\n",
      "Downloaded 8700 tweets\n",
      "Downloaded 8800 tweets\n",
      "Downloaded 8900 tweets\n",
      "Downloaded 9000 tweets\n",
      "Downloaded 9100 tweets\n",
      "Downloaded 9200 tweets\n",
      "Downloaded 9300 tweets\n",
      "Downloaded 9400 tweets\n",
      "Downloaded 9500 tweets\n",
      "Downloaded 9600 tweets\n",
      "Downloaded 9700 tweets\n",
      "Downloaded 9800 tweets\n",
      "Downloaded 9900 tweets\n",
      "Downloaded 10000 tweets\n",
      "Downloaded 10100 tweets\n",
      "Downloaded 10200 tweets\n",
      "Downloaded 10300 tweets\n",
      "Downloaded 10400 tweets\n",
      "Downloaded 10500 tweets\n",
      "Downloaded 10600 tweets\n",
      "Downloaded 10700 tweets\n",
      "Downloaded 10800 tweets\n",
      "Downloaded 10900 tweets\n",
      "Downloaded 11000 tweets\n",
      "Downloaded 11100 tweets\n",
      "Downloaded 11200 tweets\n",
      "Downloaded 11300 tweets\n",
      "Downloaded 11400 tweets\n",
      "Downloaded 11500 tweets\n",
      "Downloaded 11600 tweets\n",
      "Downloaded 11700 tweets\n",
      "Downloaded 11800 tweets\n",
      "Downloaded 11900 tweets\n",
      "Downloaded 12000 tweets\n",
      "Downloaded 12100 tweets\n",
      "Downloaded 12200 tweets\n",
      "Downloaded 12300 tweets\n",
      "Downloaded 12400 tweets\n",
      "Downloaded 12500 tweets\n",
      "Downloaded 12600 tweets\n",
      "Downloaded 12700 tweets\n",
      "Downloaded 12800 tweets\n",
      "Downloaded 12900 tweets\n",
      "Downloaded 13000 tweets\n",
      "Downloaded 13100 tweets\n",
      "Downloaded 13200 tweets\n",
      "Downloaded 13300 tweets\n",
      "Downloaded 13400 tweets\n",
      "Downloaded 13500 tweets\n",
      "Downloaded 13600 tweets\n",
      "Downloaded 13700 tweets\n",
      "Downloaded 13800 tweets\n",
      "Downloaded 13900 tweets\n",
      "Downloaded 14000 tweets\n",
      "Downloaded 14100 tweets\n",
      "Downloaded 14200 tweets\n",
      "Downloaded 14300 tweets\n",
      "Downloaded 14400 tweets\n",
      "Downloaded 14500 tweets\n",
      "Downloaded 14600 tweets\n",
      "Downloaded 14700 tweets\n",
      "Downloaded 14800 tweets\n",
      "Downloaded 14900 tweets\n",
      "Downloaded 15000 tweets\n",
      "Downloaded 15100 tweets\n",
      "Downloaded 15200 tweets\n",
      "Downloaded 15300 tweets\n",
      "Downloaded 15400 tweets\n",
      "Downloaded 15500 tweets\n",
      "Downloaded 15600 tweets\n",
      "Downloaded 15700 tweets\n",
      "Downloaded 15800 tweets\n",
      "Downloaded 15900 tweets\n",
      "Downloaded 16000 tweets\n",
      "Downloaded 16100 tweets\n",
      "Downloaded 16200 tweets\n",
      "Downloaded 16300 tweets\n",
      "Downloaded 16400 tweets\n",
      "Downloaded 16500 tweets\n",
      "Downloaded 16600 tweets\n",
      "Downloaded 16700 tweets\n",
      "Downloaded 16800 tweets\n",
      "Downloaded 16900 tweets\n",
      "Downloaded 17000 tweets\n",
      "Downloaded 17100 tweets\n",
      "Downloaded 17200 tweets\n",
      "Downloaded 17300 tweets\n",
      "Downloaded 17400 tweets\n",
      "Downloaded 17500 tweets\n",
      "Downloaded 17600 tweets\n",
      "Downloaded 17700 tweets\n",
      "Downloaded 17800 tweets\n",
      "Downloaded 17900 tweets\n",
      "Downloaded 18000 tweets\n",
      "Downloaded 18100 tweets\n",
      "Downloaded 18200 tweets\n",
      "Downloaded 18300 tweets\n",
      "Downloaded 18400 tweets\n",
      "Downloaded 18500 tweets\n",
      "Downloaded 18600 tweets\n",
      "Downloaded 18700 tweets\n",
      "Downloaded 18800 tweets\n",
      "Downloaded 18900 tweets\n",
      "Downloaded 19000 tweets\n",
      "Downloaded 19100 tweets\n",
      "Downloaded 19200 tweets\n",
      "Downloaded 19300 tweets\n",
      "Downloaded 19400 tweets\n",
      "Downloaded 19500 tweets\n",
      "Downloaded 19600 tweets\n",
      "Downloaded 19700 tweets\n",
      "Downloaded 19800 tweets\n",
      "Downloaded 19900 tweets\n",
      "Downloaded 20000 tweets\n",
      "Downloaded 20100 tweets\n",
      "Downloaded 20200 tweets\n",
      "Downloaded 20300 tweets\n",
      "Downloaded 20400 tweets\n",
      "Downloaded 20500 tweets\n",
      "Downloaded 20600 tweets\n",
      "Downloaded 20700 tweets\n",
      "Downloaded 20800 tweets\n",
      "Downloaded 20900 tweets\n",
      "Downloaded 21000 tweets\n",
      "Downloaded 21100 tweets\n",
      "Downloaded 21200 tweets\n",
      "Downloaded 21300 tweets\n",
      "Downloaded 21400 tweets\n",
      "Downloaded 21500 tweets\n",
      "Downloaded 21600 tweets\n",
      "Downloaded 21700 tweets\n",
      "Downloaded 21800 tweets\n",
      "Downloaded 21900 tweets\n",
      "Downloaded 22000 tweets\n",
      "Downloaded 22100 tweets\n",
      "Downloaded 22200 tweets\n",
      "Downloaded 22300 tweets\n",
      "Downloaded 22400 tweets\n",
      "Downloaded 22500 tweets\n",
      "Downloaded 22600 tweets\n",
      "Downloaded 22700 tweets\n",
      "Downloaded 22800 tweets\n",
      "Downloaded 22900 tweets\n",
      "Downloaded 23000 tweets\n",
      "Downloaded 23100 tweets\n",
      "Downloaded 23200 tweets\n",
      "Downloaded 23300 tweets\n",
      "Downloaded 23400 tweets\n",
      "Downloaded 23500 tweets\n",
      "Downloaded 23600 tweets\n",
      "Downloaded 23700 tweets\n",
      "Downloaded 23800 tweets\n",
      "Downloaded 23900 tweets\n",
      "Downloaded 24000 tweets\n",
      "Downloaded 24100 tweets\n",
      "Downloaded 24200 tweets\n",
      "Downloaded 24300 tweets\n",
      "Downloaded 24400 tweets\n",
      "Downloaded 24500 tweets\n",
      "Downloaded 24600 tweets\n",
      "Downloaded 24700 tweets\n",
      "Downloaded 24800 tweets\n",
      "Downloaded 24900 tweets\n",
      "Downloaded 25000 tweets\n",
      "Downloaded 25100 tweets\n",
      "Downloaded 25200 tweets\n",
      "Downloaded 25300 tweets\n",
      "Downloaded 25400 tweets\n",
      "Downloaded 25500 tweets\n",
      "Downloaded 25600 tweets\n",
      "Downloaded 25700 tweets\n",
      "Downloaded 25800 tweets\n",
      "Downloaded 25900 tweets\n",
      "Downloaded 26000 tweets\n",
      "Downloaded 26100 tweets\n",
      "Downloaded 26200 tweets\n",
      "Downloaded 26300 tweets\n",
      "Downloaded 26400 tweets\n",
      "Downloaded 26500 tweets\n",
      "Downloaded 26600 tweets\n",
      "Downloaded 26700 tweets\n",
      "Downloaded 26800 tweets\n",
      "Downloaded 26900 tweets\n",
      "Downloaded 27000 tweets\n",
      "Downloaded 27100 tweets\n",
      "Downloaded 27200 tweets\n",
      "Downloaded 27300 tweets\n",
      "Downloaded 27400 tweets\n",
      "Downloaded 27500 tweets\n",
      "Downloaded 27600 tweets\n",
      "Downloaded 27700 tweets\n",
      "Downloaded 27800 tweets\n",
      "Downloaded 27900 tweets\n",
      "Downloaded 28000 tweets\n",
      "Downloaded 28100 tweets\n",
      "Downloaded 28200 tweets\n",
      "Downloaded 28300 tweets\n",
      "Downloaded 28400 tweets\n",
      "Downloaded 28500 tweets\n",
      "Downloaded 28600 tweets\n",
      "Downloaded 28700 tweets\n",
      "Downloaded 28800 tweets\n",
      "Downloaded 28900 tweets\n",
      "Downloaded 29000 tweets\n",
      "Downloaded 29100 tweets\n",
      "Downloaded 29200 tweets\n",
      "Downloaded 29300 tweets\n",
      "Downloaded 29400 tweets\n",
      "Downloaded 29500 tweets\n",
      "Downloaded 29600 tweets\n",
      "Downloaded 29700 tweets\n",
      "Downloaded 29800 tweets\n",
      "Downloaded 29900 tweets\n",
      "Downloaded 30000 tweets\n",
      "Downloaded 30100 tweets\n",
      "Downloaded 30200 tweets\n",
      "Downloaded 30300 tweets\n",
      "Downloaded 30400 tweets\n",
      "Downloaded 30500 tweets\n",
      "Downloaded 30600 tweets\n",
      "Downloaded 30700 tweets\n",
      "Downloaded 30800 tweets\n",
      "Downloaded 30900 tweets\n",
      "Downloaded 31000 tweets\n",
      "Downloaded 31100 tweets\n",
      "Downloaded 31200 tweets\n",
      "Downloaded 31300 tweets\n",
      "Downloaded 31400 tweets\n",
      "Downloaded 31500 tweets\n",
      "Downloaded 31600 tweets\n",
      "Downloaded 31700 tweets\n",
      "Downloaded 31800 tweets\n",
      "Downloaded 31900 tweets\n",
      "Downloaded 32000 tweets\n",
      "Downloaded 32100 tweets\n",
      "Downloaded 32200 tweets\n",
      "Downloaded 32300 tweets\n",
      "Downloaded 32400 tweets\n",
      "Downloaded 32500 tweets\n",
      "Downloaded 32534 tweets\n",
      "No more tweets found\n",
      "Downloaded 32534 tweets, Saved to tweets.txt\n"
     ]
    }
   ],
   "source": [
    "searchQuery = '#python'  # this is what we're searching for\n",
    "maxTweets = 10000000 # Some arbitrary large number\n",
    "tweetsPerQry = 100  # this is the max the API permits\n",
    "fName = 'tweets.txt' # We'll store the tweets in a text file.\n",
    "\n",
    "\n",
    "# If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "# else default to no lower limit, go as far back as API allows\n",
    "sinceId = None\n",
    "\n",
    "# If results only below a specific ID are, set max_id to that ID.\n",
    "# else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "max_id = -1E10\n",
    "\n",
    "tweetCount = 0\n",
    "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "with open(fName, 'w') as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry)\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceId)\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                outtweets = [[tweet.user.screen_name, tweet.created_at, tweet.text.encode(\"utf-8\")]]\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "                writer.writerows(outtweets)\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000000 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 600 tweets\n",
      "Downloaded 800 tweets\n",
      "Downloaded 1000 tweets\n",
      "Downloaded 1200 tweets\n",
      "Downloaded 1400 tweets\n",
      "Downloaded 1600 tweets\n",
      "Downloaded 1800 tweets\n",
      "Downloaded 2000 tweets\n",
      "Downloaded 2200 tweets\n",
      "Downloaded 2399 tweets\n",
      "Downloaded 2599 tweets\n",
      "Downloaded 2796 tweets\n",
      "Downloaded 2996 tweets\n",
      "Downloaded 3196 tweets\n",
      "Downloaded 3233 tweets\n",
      "No more tweets found\n",
      "Downloaded 3233 tweets\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0b20fea3b553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtweetCount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloaded {0} tweets\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mmax_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweepError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "\n",
    "# maxTweets = 10000000 # Some arbitrary large number\n",
    "# tweetsPerQry = 200  # this is the max the API permits\n",
    "# fName = 'tweets.csv' # We'll store the tweets in a csv file.\n",
    "\n",
    "\n",
    "# # If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "# # else default to no lower limit, go as far back as API allows\n",
    "# sinceId = None\n",
    "\n",
    "# # If results only below a specific ID are, set max_id to that ID.\n",
    "# # else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "# max_id = -1E10\n",
    "\n",
    "# tweetCount = 0\n",
    "# print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "\n",
    "# with open(fName, 'w') as f:\n",
    "#     while tweetCount < maxTweets:\n",
    "#         try:\n",
    "#             for h in handle:\n",
    "#                 if (max_id <= 0):\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = h, count=tweetsPerQry)\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = h, count=tweetsPerQry,\n",
    "#                                             since_id=sinceId)\n",
    "#                 else:\n",
    "\n",
    "#                     if (not sinceId):\n",
    "#                         new_tweets = api.user_timeline(screen_name = h, count=tweetsPerQry,\n",
    "#                                             max_id=str(max_id - 1))\n",
    "#                     else:\n",
    "#                         new_tweets = api.user_timeline(screen_name = h, count=tweetsPerQry,\n",
    "#                                             max_id=str(max_id - 1),\n",
    "#                                             since_id=sinceId)\n",
    "#                 if not new_tweets:\n",
    "#                     print(\"No more tweets found\")\n",
    "#                     break\n",
    "#                 for tweet in new_tweets:\n",
    "#                     outtweets = [[tweet.user.screen_name, tweet.created_at, tweet.text.encode(\"utf-8\")]]\n",
    "#                     writer = csv.writer(f)\n",
    "#                     writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "#                     writer.writerows(outtweets)\n",
    "              \n",
    "#             tweetCount += len(new_tweets)\n",
    "#             print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "#             max_id = new_tweets[-1].id  \n",
    "\n",
    "#         except tweepy.TweepError as e:\n",
    "#             # Just exit if any error\n",
    "#             print(\"some error : \" + str(e))\n",
    "#             break\n",
    "\n",
    "# print (\"\\n Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = pd.read_csv('tweets.csv')\n",
    "all_tweets['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
