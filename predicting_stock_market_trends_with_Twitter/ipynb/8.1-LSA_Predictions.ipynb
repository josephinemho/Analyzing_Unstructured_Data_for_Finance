{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 -- LSA Predictions\n",
    "\n",
    "Prepare data for **Singular Value Decomposition (SVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load lib codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter/ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter/')\n",
    "\n",
    "from lib import *\n",
    "from lib.twitter_keys import my_keys\n",
    "# suppress_warnings()\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tfidf = pd.read_pickle('../predicting_stock_market_trends_with_Twitter/data/X_tfidf.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_AAPL_le = pd.read_pickle('../predicting_stock_market_trends_with_Twitter/data/y_AAPL_le.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD does what you tell it to do, so keep components empty so it does it all. PCA does it all and then returns the important ones to you. Generally, you want to use SVD when you have more columns than rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD = TruncatedSVD(100)\n",
    "latent_semantic_analysis = SVD.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evr = SVD.explained_variance_ratio_\n",
    "x = list(range(len(evr)))\n",
    "plt.plot(x, np.cumsum(evr))\n",
    "plt.bar(x, evr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsa_df = pd.DataFrame(latent_semantic_analysis, columns = X_tfidf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_latent_semantic_analysis(n_components, vectorizer):\n",
    "    SVD = TruncatedSVD(n_components)\n",
    "    component_names = [\"component_\"+str(i+1) for i in range(n_components)]\n",
    "    latent_semantic_analysis = pd.DataFrame(SVD.fit_transform(document_term_matrix),\n",
    "                                            index = corpus.index,\n",
    "                                            columns = component_names)\n",
    "    vocabulary_expression = pd.DataFrame(SVD.components_,\n",
    "                                         index = component_names,\n",
    "                                         columns = vectorizer.get_feature_names())\n",
    "    return latent_semantic_analysis, vocabulary_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis, vocabulary_expression = perform_latent_semantic_analysis(2, naive_vectorizer)\n",
    "latent_semantic_analysis['text'] = corpus['text']\n",
    "latent_semantic_analysis['book'] = corpus['book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'inverse_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4e5ca8c920e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_AAPL_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'inverse_transform'"
     ]
    }
   ],
   "source": [
    "y_AAPL_le.inverse_transform(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
