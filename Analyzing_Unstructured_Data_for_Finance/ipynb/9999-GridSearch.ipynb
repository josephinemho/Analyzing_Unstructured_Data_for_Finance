{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 9 -- Predictive Modeling\n",
    "\n",
    "Prepare data for **Singular Value Decomposition (SVD)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load lib codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Portfolio/Analyzing_Unstructured_Data_for_Finance/ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/work/Portfolio/predicting_stock_market_trends_with_Twitter/')\n",
    "\n",
    "from lib import *\n",
    "from lib.twitter_keys import my_keys\n",
    "# suppress_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO IT ON RAW DATA --> TFIDF TO LOGISTIC REGRESSION --> GRIDSEARCH TUNE LOG REG & TRY RF, SVC, KNN.\n",
    "\n",
    "* THEN do a GridSearch on the best one\n",
    "* THEN CIRCLE BCAK AND EDA ON CLUSTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = joblib.load('../Analyzing_Unstructured_Data_for_Finance/data/4.X.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = joblib.load('../Analyzing_Unstructured_Data_for_Finance/data/5.y_le.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77258,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77258,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization: The problem of overfitting**\n",
    "\n",
    "You don't want your hypothesis to have high bias (underfit) or take too many features and the learned hypthesis will learn the training set really well, but not generalize to new data as well (predict prices on new data). \n",
    "\n",
    "If you think overfitting is occurring, you can REGULARIZATION. Keep all features, but reduce the magnitude. This method works well when you have LOTS of features that contribute a little bit to the value of y, so you might not want to throw them away. Regularization (LASSO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=20, stop_words='english')),\n",
    "    ('lr', LogisticRegression(C=1E10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_svd_lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=20, stop_words='english')),\n",
    "    ('svd', TruncatedSVD(n_components = 10, random_state=42)),\n",
    "    ('lr', LogisticRegression(C=1E10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lr_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65022392503041759"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_lr_pipe.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty':['l2','l1'],\n",
    "    'C':np.logspace(-3,3,30)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_lr = GridSearchCV(LogisticRegression(random_state=42, n_jobs=-1), param_grid=params, n_jobs=-1,cv=StratifiedShuffleSplit(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': array([  1.00000e-03,   1.61026e-03,   2.59294e-03,   4.17532e-03,\n",
       "         6.72336e-03,   1.08264e-02,   1.74333e-02,   2.80722e-02,\n",
       "         4.52035e-02,   7.27895e-02,   1.17210e-01,   1.88739e-01,\n",
       "         3.03920e-01,   4.89390e-01,   7.88046e-01,   1.26896e+00,\n",
       "         2.0433...5e+02,   2.39503e+02,   3.85662e+02,\n",
       "         6.21017e+02,   1.00000e+03]), 'penalty': ['l2', 'l1']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "gs_lr.fit(X_train,y_train)\n",
    "\n",
    "end = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.2689610031679222, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_lr_lr.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.45732</td>\n",
       "      <td>0.56292</td>\n",
       "      <td>0.512088</td>\n",
       "      <td>0.584101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.000864768</td>\n",
       "      <td>0.000838161</td>\n",
       "      <td>0.000855446</td>\n",
       "      <td>0.000875425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.898346</td>\n",
       "      <td>0.898346</td>\n",
       "      <td>0.898309</td>\n",
       "      <td>0.898309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.898444</td>\n",
       "      <td>0.898975</td>\n",
       "      <td>0.89893</td>\n",
       "      <td>0.899649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1.26896</td>\n",
       "      <td>1.26896</td>\n",
       "      <td>2.04336</td>\n",
       "      <td>3.29034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1.26896100317, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1.26896100317, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 2.04335971786, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 3.29034456231, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.898364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.898536</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>0.899046</td>\n",
       "      <td>0.89972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.899283</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.898732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.898434</td>\n",
       "      <td>0.898965</td>\n",
       "      <td>0.899005</td>\n",
       "      <td>0.899557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.897629</td>\n",
       "      <td>0.897629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.898474</td>\n",
       "      <td>0.898842</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.899802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.89818</td>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.897813</td>\n",
       "      <td>0.89671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.898495</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.899087</td>\n",
       "      <td>0.899639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.898548</td>\n",
       "      <td>0.899099</td>\n",
       "      <td>0.898916</td>\n",
       "      <td>0.899283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.898331</td>\n",
       "      <td>0.898719</td>\n",
       "      <td>0.89874</td>\n",
       "      <td>0.899434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.89818</td>\n",
       "      <td>0.898732</td>\n",
       "      <td>0.898364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>0.898372</td>\n",
       "      <td>0.899026</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.899577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.898732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>0.898454</td>\n",
       "      <td>0.898985</td>\n",
       "      <td>0.898699</td>\n",
       "      <td>0.899884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>0.898548</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.898364</td>\n",
       "      <td>0.898364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>0.898474</td>\n",
       "      <td>0.899046</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.899618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>0.89818</td>\n",
       "      <td>0.897078</td>\n",
       "      <td>0.897997</td>\n",
       "      <td>0.897997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>0.898495</td>\n",
       "      <td>0.899128</td>\n",
       "      <td>0.899067</td>\n",
       "      <td>0.89972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>0.898548</td>\n",
       "      <td>0.899099</td>\n",
       "      <td>0.898916</td>\n",
       "      <td>0.898916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>0.898372</td>\n",
       "      <td>0.898924</td>\n",
       "      <td>0.898781</td>\n",
       "      <td>0.899536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0252435</td>\n",
       "      <td>0.0232837</td>\n",
       "      <td>0.0153261</td>\n",
       "      <td>0.0166793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>3.345e-05</td>\n",
       "      <td>3.5341e-05</td>\n",
       "      <td>4.31244e-05</td>\n",
       "      <td>3.21161e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000173387</td>\n",
       "      <td>0.000633742</td>\n",
       "      <td>0.000427484</td>\n",
       "      <td>0.000692817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>6.21159e-05</td>\n",
       "      <td>0.000118474</td>\n",
       "      <td>0.000133318</td>\n",
       "      <td>0.0001273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       30  \\\n",
       "mean_fit_time                                     0.45732   \n",
       "mean_score_time                               0.000864768   \n",
       "mean_test_score                                  0.898346   \n",
       "mean_train_score                                 0.898444   \n",
       "param_C                                           1.26896   \n",
       "param_penalty                                          l2   \n",
       "params              {'C': 1.26896100317, 'penalty': 'l2'}   \n",
       "rank_test_score                                         1   \n",
       "split0_test_score                                0.898364   \n",
       "split0_train_score                               0.898536   \n",
       "split1_test_score                                0.898364   \n",
       "split1_train_score                               0.898434   \n",
       "split2_test_score                                0.897997   \n",
       "split2_train_score                               0.898474   \n",
       "split3_test_score                                 0.89818   \n",
       "split3_train_score                               0.898495   \n",
       "split4_test_score                                0.898548   \n",
       "split4_train_score                               0.898331   \n",
       "split5_test_score                                0.898364   \n",
       "split5_train_score                               0.898372   \n",
       "split6_test_score                                0.898364   \n",
       "split6_train_score                               0.898454   \n",
       "split7_test_score                                0.898548   \n",
       "split7_train_score                               0.898474   \n",
       "split8_test_score                                 0.89818   \n",
       "split8_train_score                               0.898495   \n",
       "split9_test_score                                0.898548   \n",
       "split9_train_score                               0.898372   \n",
       "std_fit_time                                    0.0252435   \n",
       "std_score_time                                  3.345e-05   \n",
       "std_test_score                                0.000173387   \n",
       "std_train_score                               6.21159e-05   \n",
       "\n",
       "                                                       31  \\\n",
       "mean_fit_time                                     0.56292   \n",
       "mean_score_time                               0.000838161   \n",
       "mean_test_score                                  0.898346   \n",
       "mean_train_score                                 0.898975   \n",
       "param_C                                           1.26896   \n",
       "param_penalty                                          l1   \n",
       "params              {'C': 1.26896100317, 'penalty': 'l1'}   \n",
       "rank_test_score                                         1   \n",
       "split0_test_score                                0.897997   \n",
       "split0_train_score                               0.899128   \n",
       "split1_test_score                                0.899283   \n",
       "split1_train_score                               0.898965   \n",
       "split2_test_score                                0.897997   \n",
       "split2_train_score                               0.898842   \n",
       "split3_test_score                                0.897997   \n",
       "split3_train_score                               0.898985   \n",
       "split4_test_score                                0.899099   \n",
       "split4_train_score                               0.898719   \n",
       "split5_test_score                                 0.89818   \n",
       "split5_train_score                               0.899026   \n",
       "split6_test_score                                0.898364   \n",
       "split6_train_score                               0.898985   \n",
       "split7_test_score                                0.898364   \n",
       "split7_train_score                               0.899046   \n",
       "split8_test_score                                0.897078   \n",
       "split8_train_score                               0.899128   \n",
       "split9_test_score                                0.899099   \n",
       "split9_train_score                               0.898924   \n",
       "std_fit_time                                    0.0232837   \n",
       "std_score_time                                 3.5341e-05   \n",
       "std_test_score                                0.000633742   \n",
       "std_train_score                               0.000118474   \n",
       "\n",
       "                                                       32  \\\n",
       "mean_fit_time                                    0.512088   \n",
       "mean_score_time                               0.000855446   \n",
       "mean_test_score                                  0.898309   \n",
       "mean_train_score                                  0.89893   \n",
       "param_C                                           2.04336   \n",
       "param_penalty                                          l2   \n",
       "params              {'C': 2.04335971786, 'penalty': 'l2'}   \n",
       "rank_test_score                                         3   \n",
       "split0_test_score                                0.898364   \n",
       "split0_train_score                               0.899046   \n",
       "split1_test_score                                0.898364   \n",
       "split1_train_score                               0.899005   \n",
       "split2_test_score                                0.897629   \n",
       "split2_train_score                               0.898985   \n",
       "split3_test_score                                0.897813   \n",
       "split3_train_score                               0.899087   \n",
       "split4_test_score                                0.898916   \n",
       "split4_train_score                                0.89874   \n",
       "split5_test_score                                0.898732   \n",
       "split5_train_score                               0.898944   \n",
       "split6_test_score                                0.897997   \n",
       "split6_train_score                               0.898699   \n",
       "split7_test_score                                0.898364   \n",
       "split7_train_score                               0.898944   \n",
       "split8_test_score                                0.897997   \n",
       "split8_train_score                               0.899067   \n",
       "split9_test_score                                0.898916   \n",
       "split9_train_score                               0.898781   \n",
       "std_fit_time                                    0.0153261   \n",
       "std_score_time                                4.31244e-05   \n",
       "std_test_score                                0.000427484   \n",
       "std_train_score                               0.000133318   \n",
       "\n",
       "                                                       34  \n",
       "mean_fit_time                                    0.584101  \n",
       "mean_score_time                               0.000875425  \n",
       "mean_test_score                                  0.898309  \n",
       "mean_train_score                                 0.899649  \n",
       "param_C                                           3.29034  \n",
       "param_penalty                                          l2  \n",
       "params              {'C': 3.29034456231, 'penalty': 'l2'}  \n",
       "rank_test_score                                         3  \n",
       "split0_test_score                                0.898364  \n",
       "split0_train_score                                0.89972  \n",
       "split1_test_score                                0.898732  \n",
       "split1_train_score                               0.899557  \n",
       "split2_test_score                                0.897629  \n",
       "split2_train_score                               0.899802  \n",
       "split3_test_score                                 0.89671  \n",
       "split3_train_score                               0.899639  \n",
       "split4_test_score                                0.899283  \n",
       "split4_train_score                               0.899434  \n",
       "split5_test_score                                0.898364  \n",
       "split5_train_score                               0.899577  \n",
       "split6_test_score                                0.898732  \n",
       "split6_train_score                               0.899884  \n",
       "split7_test_score                                0.898364  \n",
       "split7_train_score                               0.899618  \n",
       "split8_test_score                                0.897997  \n",
       "split8_train_score                                0.89972  \n",
       "split9_test_score                                0.898916  \n",
       "split9_train_score                               0.899536  \n",
       "std_fit_time                                    0.0166793  \n",
       "std_score_time                                3.21161e-05  \n",
       "std_test_score                                0.000692817  \n",
       "std_train_score                                 0.0001273  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gs_lr.cv_results_)\n",
    "results[results['rank_test_score'] < 5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.898979501809\n",
      "predict_proba: [[ 0.95657806  0.02225322  0.02116871]\n",
      " [ 0.96692168  0.02142833  0.01165   ]\n",
      " [ 0.86838372  0.05792451  0.07369177]\n",
      " ..., \n",
      " [ 0.889696    0.08866285  0.02164115]\n",
      " [ 0.92811989  0.0269709   0.04490921]\n",
      " [ 0.95176279  0.02382861  0.0244086 ]]\n"
     ]
    }
   ],
   "source": [
    "print('score:', gs_lr.best_estimator_.score(X, y))\n",
    "print('predict_proba:', gs_lr.best_estimator_.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = gs_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12247,     4,     0],\n",
       "       [  962,     4,     0],\n",
       "       [  385,     0,     0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at f1-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     12251\n",
      "          1       0.50      0.00      0.01       966\n",
      "          2       0.00      0.00      0.00       385\n",
      "\n",
      "avg / total       0.85      0.90      0.85     13602\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THIS OVERNIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'mnb':{\n",
    "        'alpha':np.linspace(.1,1,5)\n",
    "    },\n",
    "    'lr':{\n",
    "        'C':np.logspace(-3,3,7)\n",
    "    },\n",
    "    'rf':{\n",
    "        'n_estimators': np.arange(5,15),\n",
    "        'max_depth': np.arange(1,5)\n",
    "    },\n",
    "    'svc':{\n",
    "        'C': np.logspace(-3,3,7)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'mnb':GridSearchCV(MultinomialNB(),\n",
    "                             param_grid=param_dict['mnb'],\n",
    "                             cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "    'lr':GridSearchCV(LogisticRegression(random_state=42, n_jobs=-1),\n",
    "                             param_grid=param_dict['lr'],\n",
    "                             cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "    'rf':GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                      param_grid=param_dict['rf'],\n",
    "                      cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "    'svc':GridSearchCV(SVC(random_state=42),\n",
    "                      param_grid=param_dict['svc'],\n",
    "                      cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_all_models(X,y, model_dict):\n",
    "    for model in model_dict.keys():\n",
    "        model_dict[model].fit(X,y)\n",
    "        print(\"{:5} best score: {}\".format(model, model_dict[model].best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "fit_all_models(X_train, y_train, model_dict)\n",
    "\n",
    "end = datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'mnb':{\n",
    "        'alpha':np.linspace(.1,1,5)\n",
    "    },\n",
    "    'lr':{\n",
    "        'C':np.logspace(-3,3,7)\n",
    "    },\n",
    "    'rf':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'mnb':GridSearchCV(MultinomialNB(),\n",
    "                             param_grid=param_dict['mnb'],\n",
    "                             cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "    'lr':GridSearchCV(LogisticRegression(),\n",
    "                             param_grid=param_dict['lr'],\n",
    "                             cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "    'rf':GridSearchCV(RandomForestClassifier(),\n",
    "                      param_grid=param_dict['rf'],\n",
    "                      cv=StratifiedShuffleSplit(n_splits=5, random_state=42)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_all_models(X,y, model_dict):\n",
    "    for model in model_dict.keys():\n",
    "        model_dict[model].fit(X,y)\n",
    "        print(\"{:5} best score: {}\".format(model, model_dict[model].best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr    best score: 0.8982539974269436\n",
      "mnb   best score: 0.8983642712736629\n",
      "rf    best score: 0.8863811799301599\n"
     ]
    }
   ],
   "source": [
    "fit_all_models(X_train, y_train, model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = joblib.load('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down_df = pd.DataFrame(X_train.todense()[y==0], columns=tfidf.get_feature_names())\n",
    "neutral_df = pd.DataFrame(X_train.todense()[y==1], columns=tfidf.get_feature_names())\n",
    "up_df = pd.DataFrame(X_train.todense()[y==2], columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down_df.sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutral_df.sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_df.sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Shift y's by 1 so it predicts TOMORROW's close\n",
    "\n",
    "USE MNB cuz it sounds cool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**TRY XGBOOST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PULL NEW DATA FROM THESE 30 peo0ple, make new test set, use your encoder, ...9/10 tweets predicted stocks correctly... \n",
    "\n",
    "Look at tweets (time) if it went out before Close \n",
    "- tweets vs. what happened that day (up/ddown/etc) vs. prediction (up/down)\n",
    "- do for every tweet\n",
    "- put in timestamp (0-24)\n",
    "    - adjust it so everyone is on the same timestamp\n",
    "    - chunk data \n",
    "    - see what the accuracy was in the morning vs after market has closed - does my model accuracy change? \n",
    "        - intuition: if tweets were after market closed, thats why scores are so good?\n",
    "        - OR NOT\n",
    "        CAN I LOOK AT THESE TWEETS BEFORE THE MARKET OPENS AND PREDICT WHAT HAPPENS\n",
    "        \n",
    "        IDENTIFIED THE 30 PEOPLE TO LISTEN TO\n",
    "        - USE LSA to find more people to listen to (who tweets similar - influencers)\n",
    "       \n",
    "       \n",
    "       \n",
    "# ENSEMBLING\n",
    "Building ensemble models based on chunking hours of the day to create new featurs (is NY market open? China? Day of week?)\n",
    "- can you chunk your input data (Xy grouped together) into a couple different SMARTLY chosen chunks and build a diff model for each one. \n",
    "- one model for: is it morning and NYC hasnt opened yet?\n",
    "- one model for: amrket is open (morning), (evening), close\n",
    "\n",
    "COMPLETELY SPLIT YOUR X's and Y's BEFORE doing anything to it. Is Twitter reactionary or causal? Do you get a higher/lower score? \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
